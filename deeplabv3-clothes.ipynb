{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed26e30c-9e9c-4d1c-9439-6c0327170c0c",
   "metadata": {},
   "source": [
    "# Clothing Segmentation\n",
    "### (with human parsing) by DeepLabV3 with ResNet101 Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ee7bd-a640-4e2a-8640-7448956ef97e",
   "metadata": {},
   "source": [
    "## Requirements Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64916668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:24:48.970360Z",
     "iopub.status.busy": "2025-12-19T18:24:48.970045Z",
     "iopub.status.idle": "2025-12-19T18:27:24.974424Z",
     "shell.execute_reply": "2025-12-19T18:27:24.973498Z",
     "shell.execute_reply.started": "2025-12-19T18:24:48.970336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.1 which is incompatible.\n",
      "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision datasets tqdm -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087432b1-ad75-4bd2-ad3d-ee1276e62a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:27:24.976494Z",
     "iopub.status.busy": "2025-12-19T18:27:24.976203Z",
     "iopub.status.idle": "2025-12-19T18:27:28.931788Z",
     "shell.execute_reply": "2025-12-19T18:27:28.930911Z",
     "shell.execute_reply.started": "2025-12-19T18:27:24.976463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install albumentations -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f119f-eb63-44f4-9741-e0020cbf5da8",
   "metadata": {},
   "source": [
    "### Upload to HF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d5850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:27:28.933484Z",
     "iopub.status.busy": "2025-12-19T18:27:28.933162Z",
     "iopub.status.idle": "2025-12-19T18:27:29.566107Z",
     "shell.execute_reply": "2025-12-19T18:27:29.565493Z",
     "shell.execute_reply.started": "2025-12-19T18:27:28.933444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea92134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:27:29.568057Z",
     "iopub.status.busy": "2025-12-19T18:27:29.567765Z",
     "iopub.status.idle": "2025-12-19T18:27:31.657338Z",
     "shell.execute_reply": "2025-12-19T18:27:31.656709Z",
     "shell.execute_reply.started": "2025-12-19T18:27:29.568036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "def upload_to_hf(model, val_history, repo_id):\n",
    "\n",
    "    folder = f\"deeplab_model_checkpoint\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Save model state dict (PyTorch format)\n",
    "    model_path = os.path.join(folder, 'model.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    \n",
    "    metrics_path = os.path.join(folder,\"val_metrics.json\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(val_history, f, indent=2)\n",
    "\n",
    "    try:\n",
    "        api.upload_folder(\n",
    "            repo_id=repo_id,\n",
    "            folder_path=folder,\n",
    "            path_in_repo=folder,\n",
    "        )\n",
    "        print(f\"✅ Uploaded to HuggingFace repo: {repo_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to push to HuggingFace: {e}\")\n",
    "        print(f\"   Model saved locally at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41275ff3-6334-4d0d-b15e-3f563dd9a0ab",
   "metadata": {},
   "source": [
    "#### Test HF Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c443a0a-c71d-46da-8bb0-734a1627982f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:27:31.658589Z",
     "iopub.status.busy": "2025-12-19T18:27:31.658149Z",
     "iopub.status.idle": "2025-12-19T18:27:40.240134Z",
     "shell.execute_reply": "2025-12-19T18:27:40.239402Z",
     "shell.execute_reply.started": "2025-12-19T18:27:31.658551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1653fc2145dc4aacb827f4b2f4e61d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b7bdc69e6744158eb1a802543dc4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to HuggingFace repo: oshaban/deeplabv3_clothes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import HfApi, Repository, login\n",
    "\n",
    "hf_token = \"<hf_token>\"  # get it from https://huggingface.co/settings/tokens\n",
    "login(token=hf_token)\n",
    "\n",
    "# Define a dummy PyTorch model\n",
    "class DummyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = DummyModel()\n",
    "\n",
    "# HF repo setup\n",
    "repo_id = \"oshaban/deeplabv3_clothes\"  \n",
    "local_dir = \"./hf_dummy_model\"\n",
    "\n",
    "# Create local folder\n",
    "from pathlib import Path\n",
    "Path(local_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save model + dummy config\n",
    "torch.save(model.state_dict(), f\"{local_dir}/pytorch_model.bin\")\n",
    "\n",
    "# Push to Hugging Face Hub\n",
    "try:\n",
    "    api.upload_folder(\n",
    "        repo_id=repo_id,\n",
    "        folder_path=local_dir,\n",
    "        path_in_repo=local_dir,\n",
    "    )\n",
    "    print(f\"✅ Uploaded to HuggingFace repo: {repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to push to HuggingFace: {e}\")\n",
    "    print(f\"   Model saved locally at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672bda5-e01d-42d9-a950-8c71dbcbdac3",
   "metadata": {},
   "source": [
    "#### **Trial:** Subset from iMaterialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de139ff-3e7b-44d7-b931-a9b08fe57be8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# DATASET_DIR = \"/kaggle/input/imaterialist-fashion-2020-fgvc7/train\"\n",
    "# OUTPUT_DIR = \"/kaggle/working/subset_imaterialist\"\n",
    "\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# images = os.listdir(DATASET_DIR)\n",
    "\n",
    "# # Random subset\n",
    "# subset = random.sample(images, 500)\n",
    "\n",
    "# for img in subset:\n",
    "#     shutil.copy(\n",
    "#         os.path.join(DATASET_DIR, img),\n",
    "#         os.path.join(OUTPUT_DIR, img)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b08a0-32d9-4d1b-9d11-5cae388c8ff9",
   "metadata": {},
   "source": [
    "## Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e3a656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:19.097586Z",
     "iopub.status.busy": "2025-12-19T18:28:19.096602Z",
     "iopub.status.idle": "2025-12-19T18:28:21.888483Z",
     "shell.execute_reply": "2025-12-19T18:28:21.887820Z",
     "shell.execute_reply.started": "2025-12-19T18:28:19.097551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, deeplabv3_resnet101\n",
    "from torchvision import transforms\n",
    "\n",
    "from datasets import load_dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1deee5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:34.890727Z",
     "iopub.status.busy": "2025-12-19T18:28:34.889779Z",
     "iopub.status.idle": "2025-12-19T18:28:44.015650Z",
     "shell.execute_reply": "2025-12-19T18:28:44.014976Z",
     "shell.execute_reply.started": "2025-12-19T18:28:34.890680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a902cc3eab574f8ba1ea34750eab4f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf3219136194b679005929fe7ea50b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00002-f3a663f7140ee7(…):   0%|          | 0.00/394M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd8df15583141928432c5c8ef6161c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00002-74610e243c32d5(…):   0%|          | 0.00/403M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4683c52ae19645058087412275f21282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"mattmdjaga/human_parsing_dataset\")\n",
    "\n",
    "full_train = dataset[\"train\"]\n",
    "\n",
    "# 70 / 15 / 15 split\n",
    "full_train = full_train.train_test_split(test_size=0.30, seed=42)\n",
    "val_test = full_train[\"test\"].train_test_split(test_size=0.50, seed=42)\n",
    "\n",
    "train_ds = full_train[\"train\"]\n",
    "val_ds   = val_test[\"train\"]\n",
    "test_ds  = val_test[\"test\"]\n",
    "\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cdb8e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:44.017207Z",
     "iopub.status.busy": "2025-12-19T18:28:44.016961Z",
     "iopub.status.idle": "2025-12-19T18:28:44.023806Z",
     "shell.execute_reply": "2025-12-19T18:28:44.023043Z",
     "shell.execute_reply.started": "2025-12-19T18:28:44.017183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HumanParsingDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, augment=False):\n",
    "        self.ds = hf_dataset\n",
    "        self.augment = augment\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(512, 512),\n",
    "            A.HorizontalFlip(p=0.5 if augment else 0.0),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "        image = item[\"image\"].convert(\"RGB\")\n",
    "        mask  = item[\"mask\"]\n",
    "        mask = np.array(mask, dtype=np.int64)\n",
    "        \n",
    "        augmented = self.transform(image=np.array(image), mask=mask)\n",
    "        \n",
    "        image_tensor = augmented[\"image\"]\n",
    "        mask_tensor = augmented[\"mask\"].long() \n",
    "        \n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1b66b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:44.025181Z",
     "iopub.status.busy": "2025-12-19T18:28:44.024859Z",
     "iopub.status.idle": "2025-12-19T18:28:44.050618Z",
     "shell.execute_reply": "2025-12-19T18:28:44.050097Z",
     "shell.execute_reply.started": "2025-12-19T18:28:44.025157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    HumanParsingDataset(train_ds, augment=True),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    HumanParsingDataset(val_ds),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282e2d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:44.052306Z",
     "iopub.status.busy": "2025-12-19T18:28:44.052077Z",
     "iopub.status.idle": "2025-12-19T18:28:47.064686Z",
     "shell.execute_reply": "2025-12-19T18:28:47.063845Z",
     "shell.execute_reply.started": "2025-12-19T18:28:44.052283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233M/233M [00:01<00:00, 192MB/s] \n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = deeplabv3_resnet101(weights=\"DEFAULT\")\n",
    "\n",
    "model.classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "\n",
    "if hasattr(model, 'aux_classifier'):\n",
    "    model.aux_classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310136eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:47.066674Z",
     "iopub.status.busy": "2025-12-19T18:28:47.066089Z",
     "iopub.status.idle": "2025-12-19T18:28:47.076270Z",
     "shell.execute_reply": "2025-12-19T18:28:47.075384Z",
     "shell.execute_reply.started": "2025-12-19T18:28:47.066644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/4017567697.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits: [B, C, H, W]\n",
    "        targets: [B, H, W]\n",
    "        \"\"\"\n",
    "        num_classes = logits.shape[1]\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        targets_onehot = torch.nn.functional.one_hot(\n",
    "            targets, num_classes\n",
    "        ).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        dims = (0, 2, 3)\n",
    "        intersection = torch.sum(probs * targets_onehot, dims)\n",
    "        union = torch.sum(probs + targets_onehot, dims)\n",
    "\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "ce_loss = nn.CrossEntropyLoss(ignore_index=255)\n",
    "dice_loss = DiceLoss()\n",
    "\n",
    "def combined_loss(logits, targets, dice_weight=0.4):\n",
    "    return ce_loss(logits, targets) + dice_weight * dice_loss(logits, targets)\n",
    "\n",
    "# Define optimizer and scalar\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4139d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:47.631402Z",
     "iopub.status.busy": "2025-12-19T18:28:47.630662Z",
     "iopub.status.idle": "2025-12-19T18:28:47.637313Z",
     "shell.execute_reply": "2025-12-19T18:28:47.636588Z",
     "shell.execute_reply.started": "2025-12-19T18:28:47.631371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pixel_accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    preds: [B, H, W]\n",
    "    targets: [B, H, W]\n",
    "    \"\"\"\n",
    "    valid = targets != 255\n",
    "    correct = (preds[valid] == targets[valid]).sum()\n",
    "    total = valid.sum()\n",
    "    return (correct.float() / total.float()).item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def mean_iou(preds, targets, num_classes):\n",
    "    ious = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_i = preds == cls\n",
    "        target_i = targets == cls\n",
    "\n",
    "        intersection = (pred_i & target_i).sum().float()\n",
    "        union = (pred_i | target_i).sum().float()\n",
    "\n",
    "        if union == 0:\n",
    "            continue\n",
    "\n",
    "        ious.append((intersection / union).item())\n",
    "\n",
    "    if len(ious) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return sum(ious) / len(ious)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e5cf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:49.760159Z",
     "iopub.status.busy": "2025-12-19T18:28:49.759488Z",
     "iopub.status.idle": "2025-12-19T18:28:49.766033Z",
     "shell.execute_reply": "2025-12-19T18:28:49.765210Z",
     "shell.execute_reply.started": "2025-12-19T18:28:49.760128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_iou = 0\n",
    "    count = 0\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)[\"out\"]\n",
    "        loss = combined_loss(outputs, masks)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += pixel_accuracy(preds, masks)\n",
    "        total_iou += mean_iou(preds, masks, NUM_CLASSES)\n",
    "        count += 1\n",
    "\n",
    "    return (\n",
    "        total_loss / count,\n",
    "        total_acc / count,\n",
    "        total_iou / count\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0cc54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:50.173265Z",
     "iopub.status.busy": "2025-12-19T18:28:50.172977Z",
     "iopub.status.idle": "2025-12-19T18:28:50.178790Z",
     "shell.execute_reply": "2025-12-19T18:28:50.178120Z",
     "shell.execute_reply.started": "2025-12-19T18:28:50.173238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        masks  = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)[\"out\"]\n",
    "            loss = combined_loss(outputs, masks)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7064b429-4570-48df-9f9f-26ec7eb3a571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:54.990524Z",
     "iopub.status.busy": "2025-12-19T18:28:54.990203Z",
     "iopub.status.idle": "2025-12-19T18:28:54.995252Z",
     "shell.execute_reply": "2025-12-19T18:28:54.994389Z",
     "shell.execute_reply.started": "2025-12-19T18:28:54.990497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "REPO_ID = \"oshaban/deeplabv3_clothes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11952ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:28:56.847027Z",
     "iopub.status.busy": "2025-12-19T18:28:56.846654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1550 [00:00<?, ?it/s]/tmp/ipykernel_55/3435233872.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|██████████| 1550/1550 [29:31<00:00,  1.14s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfb5bd9de1746ce88f7dfafa765137b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0688bed753164eb3813a055b0ce3461b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to HuggingFace repo: oshaban/deeplabv3_clothes\n",
      "Epoch 1/20 | Train Loss: 0.6504 | Val Loss: 0.3955 | Pixel Acc: 0.9328 | mIoU: 0.4906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1550/1550 [29:48<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7e66739c2248608ceb61c93989eb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cda78e4b624ca29066c8bcd8a8b16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to HuggingFace repo: oshaban/deeplabv3_clothes\n",
      "Epoch 2/20 | Train Loss: 0.3667 | Val Loss: 0.3498 | Pixel Acc: 0.9368 | mIoU: 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1550/1550 [29:48<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5957289e44c041f7ab283d129729f0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62da69450a0949949bfc991ebd600211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to HuggingFace repo: oshaban/deeplabv3_clothes\n",
      "Epoch 3/20 | Train Loss: 0.3308 | Val Loss: 0.3519 | Pixel Acc: 0.9339 | mIoU: 0.5036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1550/1550 [29:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae984c3509f4e9384c316e81a410a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837eda696edb4611b56b3147f499480e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to HuggingFace repo: oshaban/deeplabv3_clothes\n",
      "Epoch 4/20 | Train Loss: 0.3107 | Val Loss: 0.3301 | Pixel Acc: 0.9401 | mIoU: 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1201/1550 [23:03<06:39,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Training...\")\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    print(\"Validation...\")\n",
    "    val_loss, val_acc, val_iou = validate(model, val_loader)\n",
    "\n",
    "    val_history = []\n",
    "\n",
    "    val_history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_iou\": val_iou\n",
    "    })\n",
    "    \n",
    "    print(\"Uploading...\")\n",
    "    upload_to_hf(model, val_history, REPO_ID)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Pixel Acc: {val_acc:.4f} | \"\n",
    "        f\"mIoU: {val_iou:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768a0c5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T16:25:05.073165Z",
     "iopub.status.idle": "2025-12-19T16:25:05.073446Z",
     "shell.execute_reply": "2025-12-19T16:25:05.073338Z",
     "shell.execute_reply.started": "2025-12-19T16:25:05.073317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1053191,
     "sourceId": 18237,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
